{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JjB0dTd54WG"
      },
      "source": [
        "# Homework 3: optimization of a CNN model\n",
        "The task of this homework is to optimize a CNN model for the CIFAR-100. You are free to define the architecture of the model, and the training procedure. The only contraints are:\n",
        "- It must be a `torch.nn.Module` object\n",
        "- The number of trained parameters must be less than 1 million\n",
        "- The test dataset must not be used for any step of training. It is better if don't even import it.\n",
        "- The final training notebook should run on Google Colab within a maximum 1 hour approximately.\n",
        "\n",
        "For the grading, you must use the `evaluate` function defined below. It takes a model as input, and returns the test accuracy as output.\n",
        "\n",
        "As a guideline, you are expected to **discuss** and motivate your choices regarding:\n",
        "- Model architecture\n",
        "- Hyperparameters (learning rate, batch size, etc)\n",
        "- Regularization methods\n",
        "- Optimizer\n",
        "- Validation scheme\n",
        "\n",
        "A code without any explanation of the choices will not be accepted. Test accuracy is not the only measure of success for this homework.\n",
        "\n",
        "Remember that most of the train process is randomized, store your model's weights after training and load it before the evaluation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfNvNIxz54WI"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp5Mgthn54WJ"
      },
      "source": [
        "### Loading packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uWHU_pQG54WJ",
        "outputId": "c74a6a20-870f-49dd-be68-461f6bea36ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from evaluate import evaluate\n",
        "\n",
        "# Import the best device available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "# load the data\n",
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXBRG6qX54WL"
      },
      "source": [
        "### Example of a simple CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u_zvq0_l54WL",
        "outputId": "73895251-7797-4b2b-cd92-63566ef2320f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters:  556708\n"
          ]
        }
      ],
      "source": [
        "class TinyNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TinyNet, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(8*8*64, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.relu(self.conv1(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, 2)\n",
        "        x = torch.nn.functional.relu(self.conv2(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 8*8*64)\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "print(\"Model parameters: \", sum(p.numel() for p in TinyNet().parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72vikBOB54WL"
      },
      "source": [
        "### Example of basic training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "owDg_SS654WL",
        "outputId": "f27fc6eb-9adf-4dc7-cf81-7b743f9e0ef7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 4.5914\n",
            "Epoch [2/10], Loss: 4.5974\n",
            "Epoch [3/10], Loss: 4.6317\n",
            "Epoch [4/10], Loss: 4.6144\n",
            "Epoch [5/10], Loss: 4.5923\n",
            "Epoch [6/10], Loss: 4.5894\n",
            "Epoch [7/10], Loss: 4.5210\n",
            "Epoch [8/10], Loss: 4.4610\n",
            "Epoch [9/10], Loss: 4.4117\n",
            "Epoch [10/10], Loss: 4.3461\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = TinyNet()\n",
        "model.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "for epoch in range(10):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kE9zuete54WM",
        "outputId": "dfff6f31-643c-493e-d26f-a10d232f61a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 556708 parameters\n",
            "\u001b[1m\u001b[91mAccuracy on the test set: 6.02%\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# save the model on a file\n",
        "torch.save(model.state_dict(), 'tiny_net.pt')\n",
        "\n",
        "loaded_model = TinyNet()\n",
        "loaded_model.load_state_dict(torch.load('tiny_net.pt', weights_only=True))\n",
        "evaluate(loaded_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH6RSfuA54WM"
      },
      "source": [
        "- Res net\n",
        "- bottleneck building block for deeper nets with fast training\n",
        "- idenitity shortcut\n",
        "- scheduler for learning rate. study if a plateau is present and in case reduce the lr at plateau\n",
        "- weight initialization using kaming he initialization (works better than xavier)\n",
        "- regularization using weight decay: no dropout becauase when using BN it can be avoided\n",
        "- optimizer: sdg or adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ICDeUCbnFXWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from training_utils import *"
      ],
      "metadata": {
        "id": "ygyDOpRMFocS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = None\n",
        "if torch.cuda.is_available():\n",
        "    # Requires NVIDIA GPU with CUDA installed\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "elif torch.mps.is_available():\n",
        "    # Requires Apple computer with M1 or later chip\n",
        "    DEVICE = torch.device(\"mps\")\n",
        "else:\n",
        "    # Not recommended, because it's slow. Move to Google Colab!\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "id": "F7gT3AxaHPTf",
        "outputId": "5c477617-deda-47b1-c167-28ad22d7952b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = torchvision.transforms.ToTensor()\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# load the train dataset\n",
        "train_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data/',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "# Split the dataset into 40k-10k samples for training-validation.\n",
        "from torch.utils.data import random_split\n",
        "train_dataset,  valid_dataset = random_split(\n",
        "    train_dataset,\n",
        "    lengths=[40000, 10000],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2)\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2)"
      ],
      "metadata": {
        "id": "LyManlvVSKkR",
        "outputId": "edacd1c9-6dfb-4050-996c-ea453b697cff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I define a fit function as the one used in the tp"
      ],
      "metadata": {
        "id": "Sso9U7UtFlAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(\n",
        "    model: nn.Module,\n",
        "    train_dataloader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "    device: torch.device,\n",
        "    scheduler_lr: Optional[torch.optim.lr_scheduler._LRScheduler] = None,\n",
        "    val_dataloader: Optional[DataLoader] = None\n",
        "):\n",
        "    \"\"\"\n",
        "    the fit method simply calls the train_epoch() method for a\n",
        "    specified number of epochs.\n",
        "    \"\"\"\n",
        "\n",
        "    # keep track of the losses in order to visualize them later\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train\n",
        "        train_loss = train_epoch(\n",
        "            model=model,\n",
        "            train_dataloader=train_dataloader,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        # Validate\n",
        "        if val_dataloader is not None:\n",
        "            val_loss, val_accuracy = predict(\n",
        "                model=model, test_dataloader=val_dataloader, device=device, verbose=False\n",
        "            )\n",
        "            val_losses.append(val_loss)\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            print(\n",
        "                f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, Val Accuracy={val_accuracy:.0f}%\"\n",
        "            )\n",
        "        else:\n",
        "            print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}\")\n",
        "        # LR scheduler\n",
        "        if scheduler_lr is not None:\n",
        "            scheduler_lr.step(metrics=val_loss)\n",
        "\n",
        "    return train_losses, val_losses, val_accuracies"
      ],
      "metadata": {
        "id": "yC91-AavFV9g"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture I choose is a ResNet. ResNets as we have seen in class are very good network to perform image classification tasks.\n",
        "The one I choose is a residual block ResNEt with a skip connection.\n",
        " Skip connection is important because it allows to have deep networks, which offer better performance, without the problem of the vanishing gradient."
      ],
      "metadata": {
        "id": "0JksOCq_GkI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I define the residual block of the ResNet.\n",
        "My block is a 3-layer block with a bottleneck. I choose this structure because it allows to hava e deep network but still with manageble training times.\n",
        "Each layer is made up of a convolution, a batch normalization and a ReLu used as activation function, in this order.\n",
        "The three covolutions used are the following:\n",
        "- 1x1 convolution layer to reduce dimensions\n",
        "- 3x3 (bottleneck) convolution layer on the reduced dimension\n",
        "- 1x1 convolution to restore the dimension"
      ],
      "metadata": {
        "id": "8kkDLmfeGH-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        # First layer: 1x1 reduce dimension\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels = in_planes,\n",
        "            out_channels = planes//2,\n",
        "            kernel_size=1,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes//2)\n",
        "\n",
        "        # Second layer: 3x3 bottleneck\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes//2,\n",
        "            planes//2,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "            bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes//2)\n",
        "\n",
        "        # Third layer: 1x1 restore dimension\n",
        "        self.conv3 = nn.Conv2d(\n",
        "          in_channels = planes//2,\n",
        "          out_channels = planes,\n",
        "          kernel_size=1,\n",
        "          stride=stride,\n",
        "          padding=1,\n",
        "          bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        # skip when dimensions match\n",
        "        self.skip = nn.Sequential()\n",
        "        # skip when dimensions don't match\n",
        "        if in_planes != planes or stride > 1:\n",
        "            self.skip = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x += self.skip(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "M-4bHASHHiP3"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I write the network."
      ],
      "metadata": {
        "id": "N7c-RqxJMUzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=100):\n",
        "        super().__init__()\n",
        "        self.in_planes = 32\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(1024, num_classes)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        # Iterate through all model parameters\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):  # Initialize Conv2d weights\n",
        "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):  # Initialize BatchNorm weights\n",
        "                torch.nn.init.constant_(m.weight, 1)\n",
        "                torch.nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):  # Initialize Linear weights\n",
        "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "print(\"Model parameters: \", sum(p.numel() for p in ResNet(block=ResidualBlock, num_blocks=[3,4,3,3]).parameters()))\n",
        "\n"
      ],
      "metadata": {
        "id": "FqM6MWkfMaOm",
        "outputId": "85bd1762-18f1-4e31-c142-6b340ddd9e7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters:  994724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnn = ResNet(block=ResidualBlock, num_blocks=[3,4,3,3]).to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.001, momentum=0.9)\n",
        "scheduler_lr = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5)\n",
        "\n",
        "train_losses, valid_losses, valid_accs =   fit(\n",
        "        model,\n",
        "        train_dataloader = train_dataloader,\n",
        "        optimizer = optimizer,\n",
        "        epochs = 100,\n",
        "        device = DEVICE,\n",
        "        val_dataloader = valid_dataloader,\n",
        "        scheduler_lr = scheduler_lr\n",
        "    )\n",
        "plot_loss( train_losses )\n"
      ],
      "metadata": {
        "id": "m0MkwLvkRj02",
        "outputId": "631029dd-3dc5-4856-fdb8-faa3e0445a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Train Loss=2.3668, Val Loss=2.9326, Val Accuracy=29%\n",
            "Epoch 1: Train Loss=2.3689, Val Loss=2.9377, Val Accuracy=29%\n",
            "Epoch 2: Train Loss=2.3684, Val Loss=2.9532, Val Accuracy=29%\n",
            "Epoch 3: Train Loss=2.3672, Val Loss=2.9299, Val Accuracy=29%\n",
            "Epoch 4: Train Loss=2.3673, Val Loss=2.9310, Val Accuracy=29%\n",
            "Epoch 5: Train Loss=2.3644, Val Loss=2.9291, Val Accuracy=29%\n",
            "Epoch 6: Train Loss=2.3639, Val Loss=2.9268, Val Accuracy=29%\n",
            "Epoch 7: Train Loss=2.3644, Val Loss=2.9307, Val Accuracy=29%\n",
            "Epoch 8: Train Loss=2.3641, Val Loss=2.9375, Val Accuracy=29%\n",
            "Epoch 9: Train Loss=2.3615, Val Loss=2.9285, Val Accuracy=29%\n",
            "Epoch 10: Train Loss=2.3604, Val Loss=2.9301, Val Accuracy=29%\n",
            "Epoch 11: Train Loss=2.3613, Val Loss=2.9193, Val Accuracy=29%\n",
            "Epoch 12: Train Loss=2.3579, Val Loss=2.9338, Val Accuracy=29%\n",
            "Epoch 13: Train Loss=2.3620, Val Loss=2.9282, Val Accuracy=29%\n",
            "Epoch 14: Train Loss=2.3562, Val Loss=2.9256, Val Accuracy=29%\n",
            "Epoch 15: Train Loss=2.3587, Val Loss=2.9255, Val Accuracy=29%\n",
            "Epoch 16: Train Loss=2.3572, Val Loss=2.9212, Val Accuracy=29%\n",
            "Epoch 17: Train Loss=2.3558, Val Loss=2.9254, Val Accuracy=29%\n",
            "Epoch 18: Train Loss=2.3318, Val Loss=2.9175, Val Accuracy=30%\n",
            "Epoch 19: Train Loss=2.3290, Val Loss=2.9172, Val Accuracy=30%\n",
            "Epoch 20: Train Loss=2.3284, Val Loss=2.9173, Val Accuracy=30%\n",
            "Epoch 21: Train Loss=2.3280, Val Loss=2.9182, Val Accuracy=29%\n",
            "Epoch 22: Train Loss=2.3277, Val Loss=2.9177, Val Accuracy=30%\n",
            "Epoch 23: Train Loss=2.3279, Val Loss=2.9179, Val Accuracy=29%\n",
            "Epoch 24: Train Loss=2.3278, Val Loss=2.9183, Val Accuracy=30%\n",
            "Epoch 25: Train Loss=2.3268, Val Loss=2.9171, Val Accuracy=30%\n",
            "Epoch 26: Train Loss=2.3243, Val Loss=2.9170, Val Accuracy=29%\n",
            "Epoch 27: Train Loss=2.3237, Val Loss=2.9171, Val Accuracy=29%\n",
            "Epoch 28: Train Loss=2.3240, Val Loss=2.9173, Val Accuracy=29%\n",
            "Epoch 29: Train Loss=2.3242, Val Loss=2.9173, Val Accuracy=29%\n",
            "Epoch 30: Train Loss=2.3235, Val Loss=2.9174, Val Accuracy=29%\n",
            "Epoch 31: Train Loss=2.3238, Val Loss=2.9175, Val Accuracy=29%\n",
            "Epoch 32: Train Loss=2.3233, Val Loss=2.9175, Val Accuracy=29%\n",
            "Epoch 33: Train Loss=2.3240, Val Loss=2.9175, Val Accuracy=29%\n",
            "Epoch 34: Train Loss=2.3235, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 35: Train Loss=2.3238, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 36: Train Loss=2.3238, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 37: Train Loss=2.3241, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 38: Train Loss=2.3233, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 39: Train Loss=2.3235, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 40: Train Loss=2.3235, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 41: Train Loss=2.3234, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 42: Train Loss=2.3242, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 43: Train Loss=2.3238, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 44: Train Loss=2.3237, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 45: Train Loss=2.3233, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 46: Train Loss=2.3236, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 47: Train Loss=2.3234, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 48: Train Loss=2.3232, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 49: Train Loss=2.3233, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 50: Train Loss=2.3243, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 51: Train Loss=2.3236, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 52: Train Loss=2.3236, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 53: Train Loss=2.3244, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 54: Train Loss=2.3233, Val Loss=2.9176, Val Accuracy=29%\n",
            "Epoch 55: Train Loss=2.3239, Val Loss=2.9176, Val Accuracy=29%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-835c0a69c605>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscheduler_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m train_losses, valid_losses, valid_accs =   fit(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-2ef9c0980cb8>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_dataloader, optimizer, epochs, device, scheduler_lr, val_dataloader)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         train_loss = train_epoch(\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/training_utils.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# move data and target to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# zero the parameter gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}