{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JjB0dTd54WG"
      },
      "source": [
        "# Homework 3: optimization of a CNN model\n",
        "The task of this homework is to optimize a CNN model for the CIFAR-100. You are free to define the architecture of the model, and the training procedure. The only contraints are:\n",
        "- It must be a `torch.nn.Module` object\n",
        "- The number of trained parameters must be less than 1 million\n",
        "- The test dataset must not be used for any step of training. It is better if don't even import it.\n",
        "- The final training notebook should run on Google Colab within a maximum 1 hour approximately.\n",
        "\n",
        "For the grading, you must use the `evaluate` function defined below. It takes a model as input, and returns the test accuracy as output.\n",
        "\n",
        "As a guideline, you are expected to **discuss** and motivate your choices regarding:\n",
        "- Model architecture\n",
        "- Hyperparameters (learning rate, batch size, etc)\n",
        "- Regularization methods\n",
        "- Optimizer\n",
        "- Validation scheme\n",
        "\n",
        "A code without any explanation of the choices will not be accepted. Test accuracy is not the only measure of success for this homework.\n",
        "\n",
        "Remember that most of the train process is randomized, store your model's weights after training and load it before the evaluation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfNvNIxz54WI"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp5Mgthn54WJ"
      },
      "source": [
        "### Loading packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWHU_pQG54WJ",
        "outputId": "b7c67158-4cc3-40e9-b517-6701a2ac1050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:13<00:00, 12.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Using device: cuda\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from evaluate import evaluate\n",
        "\n",
        "# Import the best device available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "# load the data\n",
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXBRG6qX54WL"
      },
      "source": [
        "### Example of a simple CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_zvq0_l54WL",
        "outputId": "01e79b5e-a6e3-4810-b2e2-37878ea3322d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters:  556708\n"
          ]
        }
      ],
      "source": [
        "class TinyNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TinyNet, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(8*8*64, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.relu(self.conv1(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, 2)\n",
        "        x = torch.nn.functional.relu(self.conv2(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 8*8*64)\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "print(\"Model parameters: \", sum(p.numel() for p in TinyNet().parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72vikBOB54WL"
      },
      "source": [
        "### Example of basic training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owDg_SS654WL",
        "outputId": "526c5bcc-8c25-4aff-ddcf-ec46d7d08f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 4.5927\n",
            "Epoch [2/10], Loss: 4.5898\n",
            "Epoch [3/10], Loss: 4.5984\n",
            "Epoch [4/10], Loss: 4.5864\n",
            "Epoch [5/10], Loss: 4.5467\n",
            "Epoch [6/10], Loss: 4.5617\n",
            "Epoch [7/10], Loss: 4.4748\n",
            "Epoch [8/10], Loss: 4.2494\n",
            "Epoch [9/10], Loss: 4.2803\n",
            "Epoch [10/10], Loss: 3.9809\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = TinyNet()\n",
        "model.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "for epoch in range(10):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE9zuete54WM",
        "outputId": "340bf0cc-749f-43ae-e2c4-b1b29ec65e15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 556708 parameters\n",
            "\u001b[1m\u001b[91mAccuracy on the test set: 6.36%\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# save the model on a file\n",
        "torch.save(model.state_dict(), 'tiny_net.pt')\n",
        "\n",
        "loaded_model = TinyNet()\n",
        "loaded_model.load_state_dict(torch.load('tiny_net.pt', weights_only=True))\n",
        "evaluate(loaded_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH6RSfuA54WM"
      },
      "source": [
        "- Res net\n",
        "- bottleneck building block for deeper nets with fast training\n",
        "- idenitity shortcut\n",
        "- scheduler for learning rate. study if a plateau is present and in case reduce the lr at plateau\n",
        "- weight initialization using kaming he initialization (works better than xavier)\n",
        "- regularization using weight decay: no dropout becauase when using BN it can be avoided\n",
        "- optimizer: sdg or adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ICDeUCbnFXWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from training_utils import *\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ygyDOpRMFocS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = None\n",
        "if torch.cuda.is_available():\n",
        "    # Requires NVIDIA GPU with CUDA installed\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "elif torch.mps.is_available():\n",
        "    # Requires Apple computer with M1 or later chip\n",
        "    DEVICE = torch.device(\"mps\")\n",
        "else:\n",
        "    # Not recommended, because it's slow. Move to Google Colab!\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7gT3AxaHPTf",
        "outputId": "932d0f1f-81c7-4559-e972-ecb9a7e3174e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = torchvision.transforms.ToTensor()\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# load the train dataset\n",
        "train_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data/',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "# Split the dataset into 40k-10k samples for training-validation.\n",
        "from torch.utils.data import random_split\n",
        "train_dataset,  valid_dataset = random_split(\n",
        "    train_dataset,\n",
        "    lengths=[40000, 10000],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2)\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyManlvVSKkR",
        "outputId": "db76251c-3ab1-445a-c9de-8e1fafa51f22"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I define a fit function as the one used in the tp"
      ],
      "metadata": {
        "id": "Sso9U7UtFlAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(\n",
        "    model: nn.Module,\n",
        "    train_dataloader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "    device: torch.device,\n",
        "    scheduler_lr: Optional[torch.optim.lr_scheduler._LRScheduler] = None,\n",
        "    val_dataloader: Optional[DataLoader] = None\n",
        "):\n",
        "    \"\"\"\n",
        "    the fit method simply calls the train_epoch() method for a\n",
        "    specified number of epochs.\n",
        "    \"\"\"\n",
        "\n",
        "    # keep track of the losses in order to visualize them later\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train\n",
        "        train_loss = train_epoch(\n",
        "            model=model,\n",
        "            train_dataloader=train_dataloader,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        # Validate\n",
        "        if val_dataloader is not None:\n",
        "            val_loss, val_accuracy = predict(\n",
        "                model=model, test_dataloader=val_dataloader, device=device, verbose=False\n",
        "            )\n",
        "            val_losses.append(val_loss)\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            print(\n",
        "                f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, Val Accuracy={val_accuracy:.0f}%\"\n",
        "            )\n",
        "        else:\n",
        "            print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}\")\n",
        "        # LR scheduler\n",
        "        if scheduler_lr is not None:\n",
        "            scheduler_lr.step(metrics=val_loss)\n",
        "\n",
        "    return train_losses, val_losses, val_accuracies"
      ],
      "metadata": {
        "id": "yC91-AavFV9g"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture I choose is a ResNet. ResNets as we have seen in class are very good network to perform image classification tasks.\n",
        "The one I choose is a residual block ResNEt with a skip connection.\n",
        " Skip connection is important because it allows to have deep networks, which offer better performance, without the problem of the vanishing gradient."
      ],
      "metadata": {
        "id": "0JksOCq_GkI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I define the residual block of the ResNet.\n",
        "My block is a 3-layer block with a bottleneck. I choose this structure because it allows to hava e deep network but still with manageble training times.\n",
        "Each layer is made up of a convolution, a batch normalization and a ReLu used as activation function, in this order.\n",
        "The three covolutions used are the following:\n",
        "- 1x1 convolution layer to reduce dimensions\n",
        "- 3x3 (bottleneck) convolution layer on the reduced dimension\n",
        "- 1x1 convolution to restore the dimension"
      ],
      "metadata": {
        "id": "8kkDLmfeGH-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_planes,\n",
        "            out_channels=planes,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=planes,\n",
        "            out_channels=planes,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        # Skip connection to match dimensions when necessary\n",
        "        self.skip = nn.Sequential()\n",
        "        if stride > 1 or in_planes != planes:\n",
        "            self.skip = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=in_planes,\n",
        "                    out_channels=planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.skip(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "M-4bHASHHiP3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I write the network."
      ],
      "metadata": {
        "id": "N7c-RqxJMUzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=100):\n",
        "        super().__init__()\n",
        "        self.in_planes = 16  # Initial number of filters\n",
        "\n",
        "        # First layer: 3x3 Convolution\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # Residual layers\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "\n",
        "        # Global Average Pooling and Fully Connected Layer\n",
        "        self.linear = nn.Linear(self.in_planes, num_classes)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                torch.nn.init.constant_(m.weight, 1)\n",
        "                torch.nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        if out.size(2) > 1 and out.size(3) > 1:\n",
        "          out = F.avg_pool2d(out, out.size(3))  # Global Average Pooling only if size is >1\n",
        "        else:\n",
        "          out = F.adaptive_avg_pool2d(out, (1, 1))  # fallback to adaptive avg pooling if size is too small\n",
        "\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "print(\"Model parameters: \", sum(p.numel() for p in ResNet(block=ResidualBlock, num_blocks=[12,11,10]).parameters()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqM6MWkfMaOm",
        "outputId": "2fa58827-ce77-49db-84a9-279c211c5ec7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters:  986740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "model = ResNet(block=ResidualBlock, num_blocks=[12, 11, 10]).to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001, momentum=0.9)\n",
        "scheduler_lr = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=3)\n",
        "\n",
        "train_losses, valid_losses, valid_accs =   fit(\n",
        "        model,\n",
        "        train_dataloader = train_dataloader,\n",
        "        optimizer = optimizer,\n",
        "        epochs = 50,\n",
        "        device = DEVICE,\n",
        "        val_dataloader = valid_dataloader,\n",
        "        scheduler_lr = scheduler_lr\n",
        "    )\n",
        "plot_loss( train_losses )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m0MkwLvkRj02",
        "outputId": "83fd38bb-b7f7-45c9-af94-af1671a9a608"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n",
            "ciao\n",
            "Epoch 0: Train Loss=4.3782, Val Loss=4.3132, Val Accuracy=6%\n",
            "Epoch 1: Train Loss=3.8137, Val Loss=3.6865, Val Accuracy=12%\n",
            "Epoch 2: Train Loss=3.5255, Val Loss=3.4498, Val Accuracy=18%\n",
            "Epoch 3: Train Loss=3.2766, Val Loss=3.3265, Val Accuracy=19%\n",
            "Epoch 4: Train Loss=3.0513, Val Loss=3.2310, Val Accuracy=21%\n",
            "Epoch 5: Train Loss=2.8521, Val Loss=3.0197, Val Accuracy=26%\n",
            "Epoch 6: Train Loss=2.6604, Val Loss=2.8331, Val Accuracy=28%\n",
            "Epoch 7: Train Loss=2.4892, Val Loss=2.8923, Val Accuracy=28%\n",
            "Epoch 8: Train Loss=2.3442, Val Loss=2.7516, Val Accuracy=31%\n",
            "Epoch 9: Train Loss=2.1924, Val Loss=2.7218, Val Accuracy=32%\n",
            "Epoch 10: Train Loss=2.0816, Val Loss=2.5503, Val Accuracy=35%\n",
            "Epoch 11: Train Loss=1.9625, Val Loss=2.6076, Val Accuracy=35%\n",
            "Epoch 12: Train Loss=1.8510, Val Loss=2.5149, Val Accuracy=36%\n",
            "Epoch 13: Train Loss=1.7639, Val Loss=2.4840, Val Accuracy=37%\n",
            "Epoch 14: Train Loss=1.6715, Val Loss=2.5155, Val Accuracy=36%\n",
            "Epoch 15: Train Loss=1.5934, Val Loss=2.4553, Val Accuracy=38%\n",
            "Epoch 16: Train Loss=1.5121, Val Loss=2.4974, Val Accuracy=37%\n",
            "Epoch 17: Train Loss=1.4226, Val Loss=2.7930, Val Accuracy=34%\n",
            "Epoch 18: Train Loss=1.3648, Val Loss=2.8129, Val Accuracy=36%\n",
            "Epoch 19: Train Loss=1.2966, Val Loss=2.5532, Val Accuracy=37%\n",
            "Epoch 20: Train Loss=0.8185, Val Loss=2.1313, Val Accuracy=45%\n",
            "Epoch 21: Train Loss=0.6409, Val Loss=2.1612, Val Accuracy=45%\n",
            "Epoch 22: Train Loss=0.5562, Val Loss=2.2088, Val Accuracy=45%\n",
            "Epoch 23: Train Loss=0.4982, Val Loss=2.2547, Val Accuracy=44%\n",
            "Epoch 24: Train Loss=0.4458, Val Loss=2.3091, Val Accuracy=44%\n",
            "Epoch 25: Train Loss=0.3839, Val Loss=2.3076, Val Accuracy=44%\n",
            "Epoch 26: Train Loss=0.3724, Val Loss=2.3191, Val Accuracy=44%\n",
            "Epoch 27: Train Loss=0.3685, Val Loss=2.3230, Val Accuracy=44%\n",
            "Epoch 28: Train Loss=0.3627, Val Loss=2.3243, Val Accuracy=44%\n",
            "Epoch 29: Train Loss=0.3583, Val Loss=2.3261, Val Accuracy=44%\n",
            "Epoch 30: Train Loss=0.3561, Val Loss=2.3272, Val Accuracy=44%\n",
            "Epoch 31: Train Loss=0.3570, Val Loss=2.3264, Val Accuracy=44%\n",
            "Epoch 32: Train Loss=0.3542, Val Loss=2.3308, Val Accuracy=44%\n",
            "Epoch 33: Train Loss=0.3565, Val Loss=2.3254, Val Accuracy=44%\n",
            "Epoch 34: Train Loss=0.3561, Val Loss=2.3225, Val Accuracy=44%\n",
            "Epoch 35: Train Loss=0.3553, Val Loss=2.3275, Val Accuracy=44%\n",
            "Epoch 36: Train Loss=0.3537, Val Loss=2.3236, Val Accuracy=44%\n",
            "Epoch 37: Train Loss=0.3554, Val Loss=2.3240, Val Accuracy=43%\n",
            "Epoch 38: Train Loss=0.3545, Val Loss=2.3307, Val Accuracy=44%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1ec95878e82c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mscheduler_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m train_losses, valid_losses, valid_accs =   fit(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2ef9c0980cb8>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_dataloader, optimizer, epochs, device, scheduler_lr, val_dataloader)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         train_loss = train_epoch(\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/training_utils.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# do the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-a84329ad7a4c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b5da113db4bb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2810\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform per pixel noramlization\n",
        "\n",
        "mean = [0.5071, 0.4865, 0.4409]\n",
        "std =  [0.2673, 0.2564, 0.2762]\n",
        "\n",
        "# Define a new transform with data augmentation for training\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),  # Random crop with padding\n",
        "    transforms.RandomHorizontalFlip(),    # Randomly flip images horizontally\n",
        "    transforms.RandomRotation(15),       # Randomly rotate images\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color augmentation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)  # Normalize to CIFAR-100 stats\n",
        "])\n",
        "\n",
        "# No data augmentation for validation\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "# Fetch data and apply the new transformer\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# load the train dataset\n",
        "augmented_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data/',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=train_transform)\n",
        "\n",
        "base_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data/',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=val_transform)\n",
        "\n",
        "# Split both the augmented and not augmented dataset,\n",
        "# but take the training from the augmented and the validation from the not augmented\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "train_dataset, _ = random_split(\n",
        "    augmented_dataset,\n",
        "    lengths=[40000, 10000],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "_, valid_dataset = random_split(\n",
        "    base_dataset,\n",
        "    lengths=[40000, 10000],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2)\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2)\n"
      ],
      "metadata": {
        "id": "4Gigyapp7sG-",
        "outputId": "1e01a8f4-932e-47a0-f624-144beefe276c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "model = ResNet(block=ResidualBlock, num_blocks=[12, 11, 10]).to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001, momentum=0.9)\n",
        "scheduler_lr = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=3)\n",
        "\n",
        "train_losses, valid_losses, valid_accs =   fit(\n",
        "        model,\n",
        "        train_dataloader = train_dataloader,\n",
        "        optimizer = optimizer,\n",
        "        epochs = 50,\n",
        "        device = DEVICE,\n",
        "        val_dataloader = valid_dataloader,\n",
        "        scheduler_lr = scheduler_lr\n",
        "    )\n",
        "plot_loss( train_losses )"
      ],
      "metadata": {
        "id": "dmwXVod_AIvP",
        "outputId": "f378ef0a-7c3f-4c0d-d583-a5f585428997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n",
            "Epoch 0: Train Loss=4.5288, Val Loss=4.1722, Val Accuracy=6%\n",
            "Epoch 1: Train Loss=4.0776, Val Loss=3.9021, Val Accuracy=10%\n",
            "Epoch 2: Train Loss=3.8517, Val Loss=3.6313, Val Accuracy=14%\n",
            "Epoch 3: Train Loss=3.6666, Val Loss=3.5116, Val Accuracy=16%\n",
            "Epoch 4: Train Loss=3.5054, Val Loss=3.4877, Val Accuracy=18%\n",
            "Epoch 5: Train Loss=3.3484, Val Loss=3.3403, Val Accuracy=20%\n",
            "Epoch 6: Train Loss=3.1949, Val Loss=3.2249, Val Accuracy=22%\n",
            "Epoch 7: Train Loss=3.0449, Val Loss=2.9543, Val Accuracy=26%\n",
            "Epoch 8: Train Loss=2.9118, Val Loss=3.0402, Val Accuracy=26%\n",
            "Epoch 9: Train Loss=2.8003, Val Loss=2.6784, Val Accuracy=32%\n",
            "Epoch 10: Train Loss=2.6824, Val Loss=3.0944, Val Accuracy=27%\n",
            "Epoch 11: Train Loss=2.5988, Val Loss=2.6274, Val Accuracy=32%\n",
            "Epoch 12: Train Loss=2.5055, Val Loss=2.5529, Val Accuracy=34%\n",
            "Epoch 13: Train Loss=2.4159, Val Loss=2.4331, Val Accuracy=37%\n",
            "Epoch 14: Train Loss=2.3516, Val Loss=2.3151, Val Accuracy=39%\n",
            "Epoch 15: Train Loss=2.2701, Val Loss=2.2952, Val Accuracy=39%\n",
            "Epoch 16: Train Loss=2.2038, Val Loss=2.2282, Val Accuracy=40%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
            ": can only test a child processAssertionError\n",
            ": can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>\n",
            "Exception ignored in: Traceback (most recent call last):\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "\n",
            "    Traceback (most recent call last):\n",
            "self._shutdown_workers()  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "self._shutdown_workers()    \n",
            "if w.is_alive():  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "\n",
            "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "if w.is_alive():    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
            ": AssertionErrorcan only test a child process: \n",
            "can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Train Loss=2.1608, Val Loss=2.1915, Val Accuracy=42%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: Train Loss=2.1004, Val Loss=2.2316, Val Accuracy=41%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>\n",
            "Exception ignored in: Traceback (most recent call last):\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "\n",
            "    self._shutdown_workers()Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "self._shutdown_workers()    \n",
            "if w.is_alive():  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "\n",
            "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "if w.is_alive():\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "Traceback (most recent call last):\n",
            "AssertionError  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            ":   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "can only test a child process    if w.is_alive():\n",
            "Exception ignored in: \n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "AssertionError    : self._shutdown_workers()\n",
            "can only test a child process\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: Train Loss=2.0496, Val Loss=2.2578, Val Accuracy=42%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90><function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
            ": can only test a child process\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7860fcbdab90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Loss=2.0130, Val Loss=2.1170, Val Accuracy=45%\n",
            "Epoch 21: Train Loss=1.9643, Val Loss=2.0353, Val Accuracy=46%\n",
            "Epoch 22: Train Loss=1.9232, Val Loss=2.0889, Val Accuracy=45%\n",
            "Epoch 23: Train Loss=1.8879, Val Loss=2.2628, Val Accuracy=42%\n",
            "Epoch 24: Train Loss=1.8553, Val Loss=2.0168, Val Accuracy=46%\n",
            "Epoch 25: Train Loss=1.8182, Val Loss=1.9938, Val Accuracy=46%\n",
            "Epoch 26: Train Loss=1.7982, Val Loss=2.0302, Val Accuracy=47%\n",
            "Epoch 27: Train Loss=1.7675, Val Loss=2.0095, Val Accuracy=46%\n",
            "Epoch 28: Train Loss=1.7268, Val Loss=1.8843, Val Accuracy=50%\n",
            "Epoch 29: Train Loss=1.7108, Val Loss=1.9463, Val Accuracy=48%\n",
            "Epoch 30: Train Loss=1.6855, Val Loss=1.8855, Val Accuracy=50%\n",
            "Epoch 31: Train Loss=1.6553, Val Loss=1.9016, Val Accuracy=49%\n",
            "Epoch 32: Train Loss=1.6460, Val Loss=1.8724, Val Accuracy=50%\n",
            "Epoch 33: Train Loss=1.6193, Val Loss=1.7996, Val Accuracy=51%\n",
            "Epoch 34: Train Loss=1.5975, Val Loss=1.8750, Val Accuracy=50%\n",
            "Epoch 35: Train Loss=1.5828, Val Loss=1.9039, Val Accuracy=49%\n",
            "Epoch 36: Train Loss=1.5595, Val Loss=1.9439, Val Accuracy=49%\n",
            "Epoch 37: Train Loss=1.5510, Val Loss=1.7480, Val Accuracy=52%\n",
            "Epoch 38: Train Loss=1.5303, Val Loss=2.0231, Val Accuracy=48%\n",
            "Epoch 39: Train Loss=1.5102, Val Loss=1.7350, Val Accuracy=53%\n",
            "Epoch 40: Train Loss=1.4911, Val Loss=1.7654, Val Accuracy=53%\n",
            "Epoch 41: Train Loss=1.4878, Val Loss=1.8544, Val Accuracy=51%\n",
            "Epoch 42: Train Loss=1.4711, Val Loss=1.9924, Val Accuracy=50%\n",
            "Epoch 43: Train Loss=1.4549, Val Loss=1.7867, Val Accuracy=52%\n",
            "Epoch 44: Train Loss=1.2081, Val Loss=1.3441, Val Accuracy=62%\n",
            "Epoch 45: Train Loss=1.1270, Val Loss=1.3231, Val Accuracy=63%\n",
            "Epoch 46: Train Loss=1.0999, Val Loss=1.3264, Val Accuracy=63%\n",
            "Epoch 47: Train Loss=1.0778, Val Loss=1.3173, Val Accuracy=63%\n",
            "Epoch 48: Train Loss=1.0566, Val Loss=1.3182, Val Accuracy=63%\n",
            "Epoch 49: Train Loss=1.0451, Val Loss=1.3135, Val Accuracy=63%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Try to change regularization parameter\n",
        "- Try SGD optmizier with momentum\n",
        "- Remove the per pixel mean before feeding the images into the network\n",
        "- Retry the bottleneck architecture."
      ],
      "metadata": {
        "id": "uZsY5DQ-A7XL"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}