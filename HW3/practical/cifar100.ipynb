{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JjB0dTd54WG"
   },
   "source": [
    "# Homework 3: optimization of a CNN model\n",
    "The task of this homework is to optimize a CNN model for the CIFAR-100. You are free to define the architecture of the model, and the training procedure. The only contraints are:\n",
    "- It must be a `torch.nn.Module` object\n",
    "- The number of trained parameters must be less than 1 million\n",
    "- The test dataset must not be used for any step of training. It is better if don't even import it.\n",
    "- The final training notebook should run on Google Colab within a maximum 1 hour approximately.\n",
    "\n",
    "For the grading, you must use the `evaluate` function defined below. It takes a model as input, and returns the test accuracy as output.\n",
    "\n",
    "As a guideline, you are expected to **discuss** and motivate your choices regarding:\n",
    "- Model architecture\n",
    "- Hyperparameters (learning rate, batch size, etc)\n",
    "- Regularization methods\n",
    "- Optimizer\n",
    "- Validation scheme\n",
    "\n",
    "A code without any explanation of the choices will not be accepted. Test accuracy is not the only measure of success for this homework.\n",
    "\n",
    "Remember that most of the train process is randomized, store your model's weights after training and load it before the evaluation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfNvNIxz54WI"
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bp5Mgthn54WJ"
   },
   "source": [
    "### Loading packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWHU_pQG54WJ",
    "outputId": "a1475b74-b6ca-4534-93e1-c4e590d573c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Using device: cuda\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from evaluate import evaluate\n",
    "\n",
    "# Import the best device available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# load the data\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXBRG6qX54WL"
   },
   "source": [
    "### Example of a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_zvq0_l54WL",
    "outputId": "01e79b5e-a6e3-4810-b2e2-37878ea3322d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  556708\n"
     ]
    }
   ],
   "source": [
    "class TinyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = torch.nn.Linear(8*8*64, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.conv1(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = torch.nn.functional.relu(self.conv2(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 8*8*64)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "print(\"Model parameters: \", sum(p.numel() for p in TinyNet().parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72vikBOB54WL"
   },
   "source": [
    "### Example of basic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "owDg_SS654WL",
    "outputId": "526c5bcc-8c25-4aff-ddcf-ec46d7d08f74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.5927\n",
      "Epoch [2/10], Loss: 4.5898\n",
      "Epoch [3/10], Loss: 4.5984\n",
      "Epoch [4/10], Loss: 4.5864\n",
      "Epoch [5/10], Loss: 4.5467\n",
      "Epoch [6/10], Loss: 4.5617\n",
      "Epoch [7/10], Loss: 4.4748\n",
      "Epoch [8/10], Loss: 4.2494\n",
      "Epoch [9/10], Loss: 4.2803\n",
      "Epoch [10/10], Loss: 3.9809\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = TinyNet()\n",
    "model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kE9zuete54WM",
    "outputId": "340bf0cc-749f-43ae-e2c4-b1b29ec65e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 556708 parameters\n",
      "\u001b[1m\u001b[91mAccuracy on the test set: 6.36%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# save the model on a file\n",
    "torch.save(model.state_dict(), 'tiny_net.pt')\n",
    "\n",
    "loaded_model = TinyNet()\n",
    "loaded_model.load_state_dict(torch.load('tiny_net.pt', weights_only=True))\n",
    "evaluate(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OH6RSfuA54WM"
   },
   "source": [
    "- Res net\n",
    "- bottleneck building block for deeper nets with fast training\n",
    "- idenitity shortcut\n",
    "- scheduler for learning rate. study if a plateau is present and in case reduce the lr at plateau\n",
    "- weight initialization using kaming he initialization (works better than xavier)\n",
    "- regularization using weight decay: no dropout becauase when using BN it can be avoided\n",
    "- optimizer: sdg or adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICDeUCbnFXWW"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ygyDOpRMFocS"
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from training_utils import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7gT3AxaHPTf",
    "outputId": "ade768fa-51dc-4ba0-cc81-45153abd9732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = None\n",
    "if torch.cuda.is_available():\n",
    "    # Requires NVIDIA GPU with CUDA installed\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    # Requires Apple computer with M1 or later chip\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    # Not recommended, because it's slow. Move to Google Colab!\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LyManlvVSKkR",
    "outputId": "db76251c-3ab1-445a-c9de-8e1fafa51f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.CIFAR100(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "# Split the dataset into 40k-10k samples for training-validation.\n",
    "from torch.utils.data import random_split\n",
    "train_dataset,  valid_dataset = random_split(\n",
    "    train_dataset,\n",
    "    lengths=[40000, 10000],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2)\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sso9U7UtFlAy"
   },
   "source": [
    "I define a fit function as the one used in the tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "yC91-AavFV9g"
   },
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "    scheduler_lr: Optional[torch.optim.lr_scheduler._LRScheduler] = None,\n",
    "    val_dataloader: Optional[DataLoader] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    the fit method simply calls the train_epoch() method for a\n",
    "    specified number of epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    # keep track of the losses in order to visualize them later\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        train_loss = train_epoch(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        # Validate\n",
    "        if val_dataloader is not None:\n",
    "            val_loss, val_accuracy = predict(\n",
    "                model=model, test_dataloader=val_dataloader, device=device, verbose=False\n",
    "            )\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            print(\n",
    "                f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, Val Accuracy={val_accuracy:.0f}%\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}\")\n",
    "        # LR scheduler\n",
    "        if scheduler_lr is not None:\n",
    "            scheduler_lr.step()\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JksOCq_GkI4"
   },
   "source": [
    "The architecture I choose is a ResNet. ResNets as we have seen in class are very good network to perform image classification tasks.\n",
    "The one I choose is a residual block ResNEt with a skip connection.\n",
    " Skip connection is important because it allows to have deep networks, which offer better performance, without the problem of the vanishing gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kkDLmfeGH-U"
   },
   "source": [
    "I define the residual block of the ResNet.\n",
    "My block is a 3-layer block with a bottleneck. I choose this structure because it allows to hava e deep network but still with manageble training times.\n",
    "Each layer is made up of a convolution, a batch normalization and a ReLu used as activation function, in this order.\n",
    "The three covolutions used are the following:\n",
    "- 1x1 convolution layer to reduce dimensions\n",
    "- 3x3 (bottleneck) convolution layer on the reduced dimension\n",
    "- 1x1 convolution to restore the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "M-4bHASHHiP3"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_planes,\n",
    "            out_channels=planes,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=planes,\n",
    "            out_channels=planes,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # Skip connection to match dimensions when necessary\n",
    "        self.skip = nn.Sequential()\n",
    "        if stride > 1 or in_planes != planes:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_planes,\n",
    "                    out_channels=planes,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.skip(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7c-RqxJMUzc"
   },
   "source": [
    "Now I write the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqM6MWkfMaOm",
    "outputId": "b289bc10-b744-4277-8131-353d19e39cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  986740\n"
     ]
    }
   ],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=100):\n",
    "        super().__init__()\n",
    "        self.in_planes = 16  # Initial number of filters\n",
    "\n",
    "        # First layer: 3x3 Convolution\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Residual layers\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "\n",
    "        # Global Average Pooling and Fully Connected Layer\n",
    "        self.linear = nn.Linear(self.in_planes, num_classes)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                torch.nn.init.constant_(m.weight, 1)\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        if out.size(2) > 1 and out.size(3) > 1:\n",
    "          out = F.avg_pool2d(out, out.size(3))  # Global Average Pooling only if size is >1\n",
    "        else:\n",
    "          out = F.adaptive_avg_pool2d(out, (1, 1))  # fallback to adaptive avg pooling if size is too small\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "print(\"Model parameters: \", sum(p.numel() for p in ResNet(block=ResidualBlock, num_blocks=[12,11,10]).parameters()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "m0MkwLvkRj02",
    "outputId": "83fd38bb-b7f7-45c9-af94-af1671a9a608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n",
      "ciao\n",
      "Epoch 0: Train Loss=4.3782, Val Loss=4.3132, Val Accuracy=6%\n",
      "Epoch 1: Train Loss=3.8137, Val Loss=3.6865, Val Accuracy=12%\n",
      "Epoch 2: Train Loss=3.5255, Val Loss=3.4498, Val Accuracy=18%\n",
      "Epoch 3: Train Loss=3.2766, Val Loss=3.3265, Val Accuracy=19%\n",
      "Epoch 4: Train Loss=3.0513, Val Loss=3.2310, Val Accuracy=21%\n",
      "Epoch 5: Train Loss=2.8521, Val Loss=3.0197, Val Accuracy=26%\n",
      "Epoch 6: Train Loss=2.6604, Val Loss=2.8331, Val Accuracy=28%\n",
      "Epoch 7: Train Loss=2.4892, Val Loss=2.8923, Val Accuracy=28%\n",
      "Epoch 8: Train Loss=2.3442, Val Loss=2.7516, Val Accuracy=31%\n",
      "Epoch 9: Train Loss=2.1924, Val Loss=2.7218, Val Accuracy=32%\n",
      "Epoch 10: Train Loss=2.0816, Val Loss=2.5503, Val Accuracy=35%\n",
      "Epoch 11: Train Loss=1.9625, Val Loss=2.6076, Val Accuracy=35%\n",
      "Epoch 12: Train Loss=1.8510, Val Loss=2.5149, Val Accuracy=36%\n",
      "Epoch 13: Train Loss=1.7639, Val Loss=2.4840, Val Accuracy=37%\n",
      "Epoch 14: Train Loss=1.6715, Val Loss=2.5155, Val Accuracy=36%\n",
      "Epoch 15: Train Loss=1.5934, Val Loss=2.4553, Val Accuracy=38%\n",
      "Epoch 16: Train Loss=1.5121, Val Loss=2.4974, Val Accuracy=37%\n",
      "Epoch 17: Train Loss=1.4226, Val Loss=2.7930, Val Accuracy=34%\n",
      "Epoch 18: Train Loss=1.3648, Val Loss=2.8129, Val Accuracy=36%\n",
      "Epoch 19: Train Loss=1.2966, Val Loss=2.5532, Val Accuracy=37%\n",
      "Epoch 20: Train Loss=0.8185, Val Loss=2.1313, Val Accuracy=45%\n",
      "Epoch 21: Train Loss=0.6409, Val Loss=2.1612, Val Accuracy=45%\n",
      "Epoch 22: Train Loss=0.5562, Val Loss=2.2088, Val Accuracy=45%\n",
      "Epoch 23: Train Loss=0.4982, Val Loss=2.2547, Val Accuracy=44%\n",
      "Epoch 24: Train Loss=0.4458, Val Loss=2.3091, Val Accuracy=44%\n",
      "Epoch 25: Train Loss=0.3839, Val Loss=2.3076, Val Accuracy=44%\n",
      "Epoch 26: Train Loss=0.3724, Val Loss=2.3191, Val Accuracy=44%\n",
      "Epoch 27: Train Loss=0.3685, Val Loss=2.3230, Val Accuracy=44%\n",
      "Epoch 28: Train Loss=0.3627, Val Loss=2.3243, Val Accuracy=44%\n",
      "Epoch 29: Train Loss=0.3583, Val Loss=2.3261, Val Accuracy=44%\n",
      "Epoch 30: Train Loss=0.3561, Val Loss=2.3272, Val Accuracy=44%\n",
      "Epoch 31: Train Loss=0.3570, Val Loss=2.3264, Val Accuracy=44%\n",
      "Epoch 32: Train Loss=0.3542, Val Loss=2.3308, Val Accuracy=44%\n",
      "Epoch 33: Train Loss=0.3565, Val Loss=2.3254, Val Accuracy=44%\n",
      "Epoch 34: Train Loss=0.3561, Val Loss=2.3225, Val Accuracy=44%\n",
      "Epoch 35: Train Loss=0.3553, Val Loss=2.3275, Val Accuracy=44%\n",
      "Epoch 36: Train Loss=0.3537, Val Loss=2.3236, Val Accuracy=44%\n",
      "Epoch 37: Train Loss=0.3554, Val Loss=2.3240, Val Accuracy=43%\n",
      "Epoch 38: Train Loss=0.3545, Val Loss=2.3307, Val Accuracy=44%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1ec95878e82c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mscheduler_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m train_losses, valid_losses, valid_accs =   fit(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2ef9c0980cb8>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_dataloader, optimizer, epochs, device, scheduler_lr, val_dataloader)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         train_loss = train_epoch(\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/training_utils.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# do the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a84329ad7a4c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b5da113db4bb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2810\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "model = ResNet(block=ResidualBlock, num_blocks=[12, 11, 10]).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001, momentum=0.9)\n",
    "scheduler_lr = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=3)\n",
    "\n",
    "train_losses, valid_losses, valid_accs =   fit(\n",
    "        model,\n",
    "        train_dataloader = train_dataloader,\n",
    "        optimizer = optimizer,\n",
    "        epochs = 50,\n",
    "        device = DEVICE,\n",
    "        val_dataloader = valid_dataloader,\n",
    "        scheduler_lr = scheduler_lr\n",
    "    )\n",
    "plot_loss( train_losses )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Gigyapp7sG-",
    "outputId": "434b375b-0e21-4da7-9e68-09908e70d65c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Perform per pixel noramlization\n",
    "\n",
    "mean = [0.5071, 0.4865, 0.4409]\n",
    "std =  [0.2673, 0.2564, 0.2762]\n",
    "\n",
    "# Define a new transform with data augmentation for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # Random crop with padding\n",
    "    transforms.RandomHorizontalFlip(),    # Randomly flip images horizontally\n",
    "    transforms.RandomRotation(15),       # Randomly rotate images\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)  # Normalize to CIFAR-100 stats\n",
    "])\n",
    "\n",
    "# No data augmentation for validation\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# Fetch data and apply the new transformer\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# load the train dataset\n",
    "augmented_dataset = torchvision.datasets.CIFAR100(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform)\n",
    "\n",
    "base_dataset = torchvision.datasets.CIFAR100(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=val_transform)\n",
    "\n",
    "# Split both the augmented and not augmented dataset,\n",
    "# but take the training from the augmented and the validation from the not augmented\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "train_dataset, _ = random_split(\n",
    "    augmented_dataset,\n",
    "    lengths=[40000, 10000],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "_, valid_dataset = random_split(\n",
    "    base_dataset,\n",
    "    lengths=[40000, 10000],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2)\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dmwXVod_AIvP",
    "outputId": "6bda312d-5271-4846-f988-3329d1be360a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss=4.5341, Val Loss=4.2371, Val Accuracy=5%\n",
      "Epoch 1: Train Loss=4.1085, Val Loss=3.9244, Val Accuracy=9%\n",
      "Epoch 2: Train Loss=3.8339, Val Loss=3.6200, Val Accuracy=15%\n",
      "Epoch 3: Train Loss=3.6370, Val Loss=3.5371, Val Accuracy=15%\n",
      "Epoch 4: Train Loss=3.4863, Val Loss=3.3330, Val Accuracy=19%\n",
      "Epoch 5: Train Loss=3.3254, Val Loss=3.2018, Val Accuracy=22%\n",
      "Epoch 6: Train Loss=3.1787, Val Loss=3.2045, Val Accuracy=23%\n",
      "Epoch 7: Train Loss=3.0417, Val Loss=3.0458, Val Accuracy=24%\n",
      "Epoch 8: Train Loss=2.9036, Val Loss=2.8522, Val Accuracy=28%\n",
      "Epoch 9: Train Loss=2.7661, Val Loss=2.8008, Val Accuracy=29%\n",
      "Epoch 10: Train Loss=2.6613, Val Loss=2.8536, Val Accuracy=30%\n",
      "Epoch 11: Train Loss=2.5652, Val Loss=2.7345, Val Accuracy=31%\n",
      "Epoch 12: Train Loss=2.4693, Val Loss=2.5015, Val Accuracy=36%\n",
      "Epoch 13: Train Loss=2.3911, Val Loss=2.4936, Val Accuracy=35%\n",
      "Epoch 14: Train Loss=2.3186, Val Loss=2.4978, Val Accuracy=35%\n",
      "Epoch 15: Train Loss=2.2581, Val Loss=2.2105, Val Accuracy=41%\n",
      "Epoch 16: Train Loss=2.1825, Val Loss=2.3928, Val Accuracy=38%\n",
      "Epoch 17: Train Loss=2.1296, Val Loss=2.4000, Val Accuracy=38%\n",
      "Epoch 18: Train Loss=2.0812, Val Loss=2.1856, Val Accuracy=42%\n",
      "Epoch 19: Train Loss=2.0197, Val Loss=2.2045, Val Accuracy=42%\n",
      "Epoch 20: Train Loss=1.9764, Val Loss=2.1478, Val Accuracy=44%\n",
      "Epoch 21: Train Loss=1.9439, Val Loss=2.2091, Val Accuracy=42%\n",
      "Epoch 22: Train Loss=1.8941, Val Loss=2.0348, Val Accuracy=45%\n",
      "Epoch 23: Train Loss=1.8656, Val Loss=1.9422, Val Accuracy=48%\n",
      "Epoch 24: Train Loss=1.8199, Val Loss=2.2458, Val Accuracy=43%\n",
      "Epoch 25: Train Loss=1.7904, Val Loss=1.9659, Val Accuracy=47%\n",
      "Epoch 26: Train Loss=1.7599, Val Loss=1.8692, Val Accuracy=49%\n",
      "Epoch 27: Train Loss=1.7336, Val Loss=1.9715, Val Accuracy=48%\n",
      "Epoch 28: Train Loss=1.7062, Val Loss=2.1263, Val Accuracy=45%\n",
      "Epoch 29: Train Loss=1.6761, Val Loss=1.8912, Val Accuracy=49%\n",
      "Epoch 30: Train Loss=1.6668, Val Loss=1.9080, Val Accuracy=49%\n",
      "Epoch 31: Train Loss=1.4132, Val Loss=1.4754, Val Accuracy=58%\n",
      "Epoch 32: Train Loss=1.3400, Val Loss=1.4425, Val Accuracy=59%\n",
      "Epoch 33: Train Loss=1.3185, Val Loss=1.4279, Val Accuracy=60%\n",
      "Epoch 34: Train Loss=1.2974, Val Loss=1.4282, Val Accuracy=60%\n",
      "Epoch 35: Train Loss=1.2784, Val Loss=1.4364, Val Accuracy=60%\n",
      "Epoch 36: Train Loss=1.2651, Val Loss=1.4263, Val Accuracy=60%\n",
      "Epoch 37: Train Loss=1.2536, Val Loss=1.4170, Val Accuracy=60%\n",
      "Epoch 38: Train Loss=1.2422, Val Loss=1.4246, Val Accuracy=60%\n",
      "Epoch 39: Train Loss=1.2339, Val Loss=1.4230, Val Accuracy=60%\n",
      "Epoch 40: Train Loss=1.2258, Val Loss=1.4152, Val Accuracy=60%\n",
      "Epoch 41: Train Loss=1.2199, Val Loss=1.4138, Val Accuracy=61%\n",
      "Epoch 42: Train Loss=1.2131, Val Loss=1.4162, Val Accuracy=60%\n",
      "Epoch 43: Train Loss=1.2050, Val Loss=1.4154, Val Accuracy=61%\n",
      "Epoch 44: Train Loss=1.1867, Val Loss=1.4041, Val Accuracy=60%\n",
      "Epoch 45: Train Loss=1.1832, Val Loss=1.4188, Val Accuracy=60%\n",
      "Epoch 46: Train Loss=1.1793, Val Loss=1.4081, Val Accuracy=60%\n",
      "Epoch 47: Train Loss=1.1740, Val Loss=1.4166, Val Accuracy=60%\n",
      "Epoch 48: Train Loss=1.1521, Val Loss=1.4212, Val Accuracy=60%\n",
      "Epoch 49: Train Loss=1.1255, Val Loss=1.3867, Val Accuracy=61%\n",
      "Epoch 50: Train Loss=1.1138, Val Loss=1.3775, Val Accuracy=61%\n",
      "Epoch 51: Train Loss=1.1091, Val Loss=1.3809, Val Accuracy=61%\n",
      "Epoch 52: Train Loss=1.1082, Val Loss=1.3781, Val Accuracy=61%\n",
      "Epoch 53: Train Loss=1.1039, Val Loss=1.3750, Val Accuracy=61%\n",
      "Epoch 54: Train Loss=1.1093, Val Loss=1.3743, Val Accuracy=61%\n",
      "Epoch 55: Train Loss=1.1007, Val Loss=1.3751, Val Accuracy=62%\n",
      "Epoch 56: Train Loss=1.1025, Val Loss=1.3760, Val Accuracy=62%\n",
      "Epoch 57: Train Loss=1.0967, Val Loss=1.3747, Val Accuracy=61%\n",
      "Epoch 58: Train Loss=1.0962, Val Loss=1.3727, Val Accuracy=61%\n",
      "Epoch 59: Train Loss=1.0932, Val Loss=1.3735, Val Accuracy=61%\n",
      "Epoch 60: Train Loss=1.0950, Val Loss=1.3797, Val Accuracy=61%\n",
      "Epoch 61: Train Loss=1.0875, Val Loss=1.3764, Val Accuracy=61%\n",
      "Epoch 62: Train Loss=1.0873, Val Loss=1.3714, Val Accuracy=62%\n",
      "Epoch 63: Train Loss=1.0915, Val Loss=1.3709, Val Accuracy=61%\n",
      "Epoch 64: Train Loss=1.0864, Val Loss=1.3702, Val Accuracy=61%\n",
      "Epoch 65: Train Loss=1.0871, Val Loss=1.3736, Val Accuracy=61%\n",
      "Epoch 66: Train Loss=1.0858, Val Loss=1.3702, Val Accuracy=62%\n",
      "Epoch 67: Train Loss=1.0888, Val Loss=1.3683, Val Accuracy=62%\n",
      "Epoch 68: Train Loss=1.0780, Val Loss=1.3719, Val Accuracy=62%\n",
      "Epoch 69: Train Loss=1.0841, Val Loss=1.3700, Val Accuracy=62%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = ResNet(block=ResidualBlock, num_blocks=[12, 11, 10]).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001, momentum=0.9)\n",
    "scheduler_lr = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=3)\n",
    "\n",
    "train_losses, valid_losses, valid_accs =   fit(\n",
    "        model,\n",
    "        train_dataloader = train_dataloader,\n",
    "        optimizer = optimizer,\n",
    "        epochs = 70,\n",
    "        device = DEVICE,\n",
    "        val_dataloader = valid_dataloader,\n",
    "        scheduler_lr = scheduler_lr\n",
    "    )\n",
    "plot_loss( train_losses )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ENQ2sfK58Bdg"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resNet_dataAug_SGD.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_tcfxFkl_vmv"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_train_val_loss(train_losses, val_losses, ylim=None, loscale=False):\n",
    "    plt.plot(train_losses, color='red', label='Training Loss')\n",
    "    plt.plot(val_losses, color='blue', label='Validation Loss')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.ylim(ylim)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    if loscale:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.title(\"Loss progression across epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "DhEC254tATJJ",
    "outputId": "851c99fd-2bcf-41ff-b78f-590e65e84696"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_val_loss(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TEjX6B5GZRp"
   },
   "source": [
    "Try with cyclic LR to escape flat region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "za7AanJrGYxx",
    "outputId": "c668a582-33e5-4afd-be2b-c46e97b82bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss=6.7867, Val Loss=6.4703, Val Accuracy=1%\n",
      "Epoch 1: Train Loss=4.9529, Val Loss=4.6497, Val Accuracy=2%\n",
      "Epoch 2: Train Loss=4.5768, Val Loss=4.4920, Val Accuracy=3%\n",
      "Epoch 3: Train Loss=4.3911, Val Loss=4.2802, Val Accuracy=6%\n",
      "Epoch 4: Train Loss=4.1777, Val Loss=4.0038, Val Accuracy=9%\n",
      "Epoch 5: Train Loss=3.9966, Val Loss=3.8361, Val Accuracy=11%\n",
      "Epoch 6: Train Loss=3.8402, Val Loss=3.6464, Val Accuracy=15%\n",
      "Epoch 7: Train Loss=3.6997, Val Loss=3.5142, Val Accuracy=16%\n",
      "Epoch 8: Train Loss=3.5564, Val Loss=3.4267, Val Accuracy=19%\n",
      "Epoch 9: Train Loss=3.4123, Val Loss=3.4580, Val Accuracy=18%\n",
      "Epoch 10: Train Loss=3.2773, Val Loss=3.2092, Val Accuracy=22%\n",
      "Epoch 11: Train Loss=3.1427, Val Loss=3.1924, Val Accuracy=23%\n",
      "Epoch 12: Train Loss=3.0042, Val Loss=3.0742, Val Accuracy=25%\n",
      "Epoch 13: Train Loss=2.8720, Val Loss=2.9045, Val Accuracy=28%\n",
      "Epoch 14: Train Loss=2.7633, Val Loss=2.9067, Val Accuracy=28%\n",
      "Epoch 15: Train Loss=2.6525, Val Loss=2.5946, Val Accuracy=33%\n",
      "Epoch 16: Train Loss=2.5623, Val Loss=2.6572, Val Accuracy=32%\n",
      "Epoch 17: Train Loss=2.4680, Val Loss=2.4227, Val Accuracy=37%\n",
      "Epoch 18: Train Loss=2.3924, Val Loss=2.5052, Val Accuracy=36%\n",
      "Epoch 19: Train Loss=2.3445, Val Loss=2.7296, Val Accuracy=32%\n",
      "Epoch 20: Train Loss=2.2910, Val Loss=2.6771, Val Accuracy=33%\n",
      "Epoch 21: Train Loss=2.2281, Val Loss=2.4019, Val Accuracy=37%\n",
      "Epoch 22: Train Loss=2.2010, Val Loss=2.6049, Val Accuracy=35%\n",
      "Epoch 23: Train Loss=2.1599, Val Loss=2.3341, Val Accuracy=39%\n",
      "Epoch 24: Train Loss=2.1208, Val Loss=2.1951, Val Accuracy=42%\n",
      "Epoch 25: Train Loss=2.1037, Val Loss=2.2124, Val Accuracy=42%\n",
      "Epoch 26: Train Loss=2.0701, Val Loss=2.5010, Val Accuracy=37%\n",
      "Epoch 27: Train Loss=2.0534, Val Loss=2.4351, Val Accuracy=39%\n",
      "Epoch 28: Train Loss=2.0366, Val Loss=2.3714, Val Accuracy=39%\n",
      "Epoch 29: Train Loss=2.0020, Val Loss=2.4337, Val Accuracy=38%\n",
      "Epoch 30: Train Loss=2.0096, Val Loss=2.2467, Val Accuracy=42%\n",
      "Epoch 31: Train Loss=1.9951, Val Loss=2.1113, Val Accuracy=44%\n",
      "Epoch 32: Train Loss=1.9702, Val Loss=2.3429, Val Accuracy=39%\n",
      "Epoch 33: Train Loss=1.9737, Val Loss=2.1269, Val Accuracy=44%\n",
      "Epoch 34: Train Loss=1.9564, Val Loss=2.3098, Val Accuracy=40%\n",
      "Epoch 35: Train Loss=1.9578, Val Loss=2.2783, Val Accuracy=41%\n",
      "Epoch 36: Train Loss=1.9467, Val Loss=2.0690, Val Accuracy=46%\n",
      "Epoch 37: Train Loss=1.9393, Val Loss=2.2718, Val Accuracy=41%\n",
      "Epoch 38: Train Loss=1.9355, Val Loss=2.2999, Val Accuracy=41%\n",
      "Epoch 39: Train Loss=1.9388, Val Loss=1.9932, Val Accuracy=46%\n",
      "Epoch 40: Train Loss=1.9327, Val Loss=2.2714, Val Accuracy=41%\n",
      "Epoch 41: Train Loss=1.9232, Val Loss=2.0991, Val Accuracy=44%\n",
      "Epoch 42: Train Loss=1.9311, Val Loss=2.1714, Val Accuracy=43%\n",
      "Epoch 43: Train Loss=1.9278, Val Loss=2.3347, Val Accuracy=42%\n",
      "Epoch 44: Train Loss=1.9286, Val Loss=2.0445, Val Accuracy=44%\n",
      "Epoch 45: Train Loss=1.9346, Val Loss=2.1897, Val Accuracy=43%\n",
      "Epoch 46: Train Loss=1.9348, Val Loss=2.1473, Val Accuracy=43%\n",
      "Epoch 47: Train Loss=1.9381, Val Loss=2.4946, Val Accuracy=38%\n",
      "Epoch 48: Train Loss=1.9430, Val Loss=2.0455, Val Accuracy=45%\n",
      "Epoch 49: Train Loss=1.9331, Val Loss=2.2450, Val Accuracy=41%\n",
      "Epoch 50: Train Loss=1.9439, Val Loss=2.0226, Val Accuracy=46%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-af0b6cac243a>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscheduler_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCyclicLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m train_losses, valid_losses, valid_accs =   fit(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-3b417d72ce26>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_dataloader, optimizer, epochs, device, scheduler_lr, val_dataloader)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         train_loss = train_epoch(\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/training_utils.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m# move data and target to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ResNet(block=ResidualBlock, num_blocks=[12, 11, 10]).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "scheduler_lr = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-6, max_lr=0.1)\n",
    "\n",
    "train_losses, valid_losses, valid_accs =   fit(\n",
    "        model,\n",
    "        train_dataloader = train_dataloader,\n",
    "        optimizer = optimizer,\n",
    "        epochs = 70,\n",
    "        device = DEVICE,\n",
    "        val_dataloader = valid_dataloader,\n",
    "        scheduler_lr = scheduler_lr\n",
    "    )\n",
    "torch.save(model.state_dict(), 'resNet_dataAug_Adam_cyclicLR.pt')\n",
    "plot_train_val_loss(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "k8nhDI2zVT8g"
   },
   "outputs": [],
   "source": [
    "def custom_lr_scheduler(current_lr, new_lr, current_accucary, prev_accuracy, \n",
    "                        num_lr_reductions, patience_reductions):\n",
    "    \n",
    "    if new_lr >= current_lr:    # no update done\n",
    "        return\n",
    "\n",
    "    print(f\"Learning rate reduced to {new_lr:.6f} (Reduction #{num_lr_reductions})\")\n",
    "    if current_accucary - prev_accuracy <= 2:   # Stagnant condition\n",
    "        num_lr_reductions += 1\n",
    "        if num_lr_reductions == patience_reductions:\n",
    "            new_lr = new_lr * 100 \n",
    "            num_lr_reductions = 0\n",
    "            print(f\"Learning rate reverted to {new_lr:.6f} after {patience_reductions} reductions\")\n",
    "    else:\n",
    "        num_lr_reductions = 0\n",
    "    return new_lr, num_lr_reductions\n",
    "    \n",
    "\n",
    "def fit(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "    scheduler_lr: Optional[torch.optim.lr_scheduler.ReduceLROnPlateau] = None,\n",
    "    val_dataloader: Optional[DataLoader] = None,\n",
    "    patience_reductions: int = 3\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model and adjust learning rate dynamically using ReduceLROnPlateau.\n",
    "\n",
    "    If the validation loss stagnates for 3 reductions, revert the learning rate\n",
    "    to its original value by multiplying by 1000.\n",
    "    \"\"\"\n",
    "    # Keep track of losses for visualization\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Tracking learning rate changes\n",
    "    num_lr_reductions = 0\n",
    "    stagnant_reduction_start_lr = None\n",
    "    accuracy_at_reduction = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        train_loss = train_epoch(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validate\n",
    "        if val_dataloader is not None:\n",
    "            val_loss, val_accuracy = predict(\n",
    "                model=model, test_dataloader=val_dataloader, device=device, verbose=False\n",
    "            )\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            print(\n",
    "                f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, Val Accuracy={val_accuracy:.0f}%\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}\")\n",
    "\n",
    "        # LR scheduler logic\n",
    "        if scheduler_lr is not None:\n",
    "            # Check if the scheduler reduced LR\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            scheduler_lr.step(metrics=val_loss)\n",
    "\n",
    "            new_lr = optimizer.param_groups[0]['lr']\n",
    "            reverted_lr, num_lr_reductions = custom_lr_scheduler(current_lr, new_lr, val_accuracy, val_accuracies[epoch-1], num_lr_reductions, patience_reductions)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = reverted_lr\n",
    "            current_lr = new_lr\n",
    "            \n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MOXzQqmHZSnc",
    "outputId": "068675d3-df90-4475-caed-809b3d1a48a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss=4.4464, Val Loss=4.9246, Val Accuracy=5%\n",
      "Epoch 1: Train Loss=3.9961, Val Loss=3.7344, Val Accuracy=11%\n",
      "Epoch 2: Train Loss=3.7818, Val Loss=3.5842, Val Accuracy=14%\n",
      "Epoch 3: Train Loss=3.6028, Val Loss=3.4657, Val Accuracy=16%\n",
      "Epoch 4: Train Loss=3.4416, Val Loss=3.2868, Val Accuracy=20%\n",
      "Epoch 5: Train Loss=3.3035, Val Loss=3.2620, Val Accuracy=20%\n",
      "Epoch 6: Train Loss=3.1453, Val Loss=3.0175, Val Accuracy=25%\n",
      "Epoch 7: Train Loss=3.0059, Val Loss=2.8701, Val Accuracy=28%\n",
      "Epoch 8: Train Loss=2.8613, Val Loss=2.8197, Val Accuracy=29%\n",
      "Epoch 9: Train Loss=2.7544, Val Loss=2.8509, Val Accuracy=29%\n",
      "Epoch 10: Train Loss=2.6422, Val Loss=2.6790, Val Accuracy=32%\n",
      "Epoch 11: Train Loss=2.5528, Val Loss=2.5337, Val Accuracy=35%\n",
      "Epoch 12: Train Loss=2.4526, Val Loss=2.5085, Val Accuracy=36%\n",
      "Epoch 13: Train Loss=2.3760, Val Loss=2.4061, Val Accuracy=38%\n",
      "Epoch 14: Train Loss=2.2927, Val Loss=2.3074, Val Accuracy=39%\n",
      "Epoch 15: Train Loss=2.2411, Val Loss=2.2046, Val Accuracy=41%\n",
      "Epoch 16: Train Loss=2.1646, Val Loss=2.3140, Val Accuracy=40%\n",
      "Epoch 17: Train Loss=2.1076, Val Loss=2.1086, Val Accuracy=44%\n",
      "Epoch 18: Train Loss=2.0525, Val Loss=2.1649, Val Accuracy=43%\n",
      "Epoch 19: Train Loss=2.0029, Val Loss=2.1387, Val Accuracy=43%\n",
      "Epoch 20: Train Loss=1.9625, Val Loss=2.2210, Val Accuracy=42%\n",
      "Epoch 21: Train Loss=1.9181, Val Loss=2.0775, Val Accuracy=44%\n",
      "Epoch 22: Train Loss=1.8863, Val Loss=1.9971, Val Accuracy=47%\n",
      "Epoch 23: Train Loss=1.8477, Val Loss=2.0178, Val Accuracy=46%\n",
      "Epoch 24: Train Loss=1.8200, Val Loss=2.0961, Val Accuracy=46%\n",
      "Epoch 25: Train Loss=1.7911, Val Loss=2.0508, Val Accuracy=46%\n",
      "Epoch 26: Train Loss=1.7529, Val Loss=2.0664, Val Accuracy=46%\n",
      "Learning rate reduced to 0.001000 (Reduction #1)\n",
      "Epoch 27: Train Loss=1.5092, Val Loss=1.5377, Val Accuracy=57%\n",
      "Epoch 28: Train Loss=1.4431, Val Loss=1.5230, Val Accuracy=57%\n",
      "Epoch 29: Train Loss=1.4166, Val Loss=1.5187, Val Accuracy=58%\n",
      "Epoch 30: Train Loss=1.3933, Val Loss=1.4982, Val Accuracy=58%\n",
      "Epoch 31: Train Loss=1.3835, Val Loss=1.5123, Val Accuracy=58%\n",
      "Epoch 32: Train Loss=1.3711, Val Loss=1.4965, Val Accuracy=58%\n",
      "Epoch 33: Train Loss=1.3541, Val Loss=1.4839, Val Accuracy=59%\n",
      "Epoch 34: Train Loss=1.3454, Val Loss=1.4760, Val Accuracy=59%\n",
      "Epoch 35: Train Loss=1.3351, Val Loss=1.4884, Val Accuracy=59%\n",
      "Epoch 36: Train Loss=1.3241, Val Loss=1.4883, Val Accuracy=58%\n",
      "Epoch 37: Train Loss=1.3172, Val Loss=1.4818, Val Accuracy=59%\n",
      "Epoch 38: Train Loss=1.3119, Val Loss=1.4798, Val Accuracy=59%\n",
      "Learning rate reduced to 0.000100 (Reduction #2)\n",
      "Epoch 39: Train Loss=1.2786, Val Loss=1.4540, Val Accuracy=60%\n",
      "Epoch 40: Train Loss=1.2647, Val Loss=1.4536, Val Accuracy=59%\n",
      "Epoch 41: Train Loss=1.2608, Val Loss=1.4472, Val Accuracy=60%\n",
      "Epoch 42: Train Loss=1.2646, Val Loss=1.4518, Val Accuracy=59%\n",
      "Epoch 43: Train Loss=1.2620, Val Loss=1.4515, Val Accuracy=59%\n",
      "Epoch 44: Train Loss=1.2534, Val Loss=1.4535, Val Accuracy=59%\n",
      "Epoch 45: Train Loss=1.2552, Val Loss=1.4507, Val Accuracy=59%\n",
      "Learning rate reduced to 0.000010 (Reduction #3)\n",
      "Learning rate reverted to 1.000000 after 3 reductions\n",
      "Epoch 46: Train Loss=4.6617, Val Loss=5.2823, Val Accuracy=2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x78bc9c9feb90>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1568, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-209da6101185>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscheduler_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m train_losses, valid_losses, valid_accs =   fit(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-972707add846>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_dataloader, optimizer, epochs, device, scheduler_lr, val_dataloader, patience_reductions)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         train_loss = train_epoch(\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/training_utils.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# perform the gradient step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    121\u001b[0m             )\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             sgd(\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, fused, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_sgd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m_multi_tensor_sgd\u001b[0;34m(params, grads, momentum_buffer_list, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall_states_with_momentum_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0mbufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ResNet(block=ResidualBlock, num_blocks=[12, 11, 10]).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001, momentum=0.9)\n",
    "scheduler_lr = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=3)\n",
    "\n",
    "train_losses, valid_losses, valid_accs =   fit(\n",
    "        model,\n",
    "        train_dataloader = train_dataloader,\n",
    "        optimizer = optimizer,\n",
    "        epochs = 70,\n",
    "        device = DEVICE,\n",
    "        val_dataloader = valid_dataloader,\n",
    "        scheduler_lr = scheduler_lr,\n",
    "        patience_reductions=3\n",
    "    )\n",
    "torch.save(model.state_dict(), 'resNet_dataAug_customLR.pt')\n",
    "plot_train_val_loss(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZsY5DQ-A7XL"
   },
   "source": [
    "- Try to change regularization parameter\n",
    "- Try SGD optmizier with momentum\n",
    "- Remove the per pixel mean before feeding the images into the network\n",
    "- Retry the bottleneck architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-or-AFo-uyF",
    "outputId": "349a8082-39f3-42c4-ad82-c2085bb8c8c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu')\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=val_transform)\n",
    "\n",
    "def evaluate(model):\n",
    "    params_count = sum(p.numel() for p in model.parameters())\n",
    "    print('The model has {} parameters'.format(params_count))\n",
    "\n",
    "    if params_count > int(1e6):\n",
    "        print('The model has too many parameters! Not allowed to evaluate.')\n",
    "        return\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "    # print in bold red in a notebook\n",
    "    print('\\033[1m\\033[91mAccuracy on the test set: {}%\\033[0m'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJ8Mvuom_Y7p",
    "outputId": "a3d1252f-5a8e-45b0-fd67-d264b5841e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 986740 parameters\n",
      "\u001b[1m\u001b[91mAccuracy on the test set: 61.8%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "evaluate(loaded_model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
